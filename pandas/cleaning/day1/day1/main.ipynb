{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "4fd57f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('data1.csv')\n",
    "df.columns=['ID','Name','Email','Phone_no','Country', 'Age','Salary','Join_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8e18b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Name section\n",
    "df['Name']=(df['Name']\n",
    "            .str.title()\n",
    "            .str.strip(' ,.')\n",
    "            .replace([np.nan,'','unknown'],np.nan))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "40863a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning email\n",
    "pattern=r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    "df.loc[18,'Email']='hashir'\n",
    "\n",
    "df.loc[~df['Email'].str.fullmatch(pattern,na=False),'Email']='Invalid Mail'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "2fab0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning phone no\n",
    "\n",
    "df['Phone_no']=(df['Phone_no']\n",
    "                .str.replace(r'(x|ext\\.?).*$', '', regex=True, case=False)\n",
    "                .str.replace(r'[^0-9+\\-]', '', regex=True)\n",
    "                .str.replace(r'-{2,}', '-', regex=True)\n",
    "                .str.strip('-')\n",
    "                .apply(lambda x: '+' + x.lstrip('+0') if pd.notna(x) else x))\n",
    "\n",
    "\n",
    "# done fully using gpt//?\n",
    "\n",
    "# droping it because it is not handling perfectly\n",
    "\n",
    "df.drop(columns=['Phone_no'],inplace=True)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "3a1026d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning salary and age\n",
    "\n",
    "df[\"Salary\"]=df['Salary'].replace(np.nan,df['Salary'].mean()).astype('int')\n",
    "df['Age']=df['Age'].fillna(df['Age'].interpolate())\n",
    "df['Age']=df['Age'].replace(np.nan,df['Age'].mean()).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d62e7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3504\\3863387375.py:10: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['Join_Date'] = pd.to_datetime(df['Join_Date'], errors='coerce', infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Join_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681</td>\n",
       "      <td>Heather Davila</td>\n",
       "      <td>igill@bryant-roberts.com</td>\n",
       "      <td>Inda</td>\n",
       "      <td>50</td>\n",
       "      <td>54349</td>\n",
       "      <td>2019-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103</td>\n",
       "      <td>Margaret Campbell</td>\n",
       "      <td>bergjack@martinez-reeves.com</td>\n",
       "      <td>India</td>\n",
       "      <td>50</td>\n",
       "      <td>66604</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>395</td>\n",
       "      <td>Veronica Wilson</td>\n",
       "      <td>jeffreychavez@gmail.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>80</td>\n",
       "      <td>66604</td>\n",
       "      <td>2021-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>931</td>\n",
       "      <td>Matthew Mcguire</td>\n",
       "      <td>angelahorne@cordova.com</td>\n",
       "      <td>India</td>\n",
       "      <td>79</td>\n",
       "      <td>186523</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>498</td>\n",
       "      <td>Anne Gentry</td>\n",
       "      <td>april19@dawson.com</td>\n",
       "      <td>Pak</td>\n",
       "      <td>78</td>\n",
       "      <td>156760</td>\n",
       "      <td>2021-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1045</td>\n",
       "      <td>William Carr</td>\n",
       "      <td>scottmendez@gomez.com</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>74</td>\n",
       "      <td>91550</td>\n",
       "      <td>2021-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1096</td>\n",
       "      <td>Nicole Donovan</td>\n",
       "      <td>nmoore@hotmail.com</td>\n",
       "      <td>Germny</td>\n",
       "      <td>30</td>\n",
       "      <td>57504</td>\n",
       "      <td>2018-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1131</td>\n",
       "      <td>Deborah Brooks</td>\n",
       "      <td>Invalid Mail</td>\n",
       "      <td>Pak</td>\n",
       "      <td>30</td>\n",
       "      <td>44270</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>861</td>\n",
       "      <td>Hannah Davis</td>\n",
       "      <td>candace91@yahoo.com</td>\n",
       "      <td>Canada</td>\n",
       "      <td>30</td>\n",
       "      <td>162748</td>\n",
       "      <td>2017-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1127</td>\n",
       "      <td>Tracey Martinez</td>\n",
       "      <td>kimberlydudley@yahoo.com</td>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>12938</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID               Name                         Email        Country  \\\n",
       "0      681     Heather Davila      igill@bryant-roberts.com           Inda   \n",
       "1     1103  Margaret Campbell  bergjack@martinez-reeves.com          India   \n",
       "2      395    Veronica Wilson       jeffreychavez@gmail.com  United States   \n",
       "3      931    Matthew Mcguire       angelahorne@cordova.com          India   \n",
       "4      498        Anne Gentry            april19@dawson.com            Pak   \n",
       "...    ...                ...                           ...            ...   \n",
       "1245  1045       William Carr         scottmendez@gomez.com       Pakistan   \n",
       "1246  1096     Nicole Donovan            nmoore@hotmail.com         Germny   \n",
       "1247  1131     Deborah Brooks                  Invalid Mail            Pak   \n",
       "1248   861       Hannah Davis           candace91@yahoo.com         Canada   \n",
       "1249  1127    Tracey Martinez      kimberlydudley@yahoo.com          India   \n",
       "\n",
       "      Age  Salary  Join_Date  \n",
       "0      50   54349 2019-04-01  \n",
       "1      50   66604 2024-01-01  \n",
       "2      80   66604 2021-07-15  \n",
       "3      79  186523 2024-01-01  \n",
       "4      78  156760 2021-07-15  \n",
       "...   ...     ...        ...  \n",
       "1245   74   91550 2021-07-15  \n",
       "1246   30   57504 2018-02-05  \n",
       "1247   30   44270 2017-03-31  \n",
       "1248   30  162748 2017-07-19  \n",
       "1249   30   12938 2024-01-01  \n",
       "\n",
       "[1250 rows x 7 columns]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning time\n",
    "\n",
    "# df['Join_Date']=df['Join_Date'].str.replace(r'([+-]\\d{2}:?\\d{2}|Z)$','',regex=True)\n",
    "df['Join_Date'] = (df['Join_Date']\n",
    "                   .astype(str)\n",
    "                   .str.replace(r'([+-]\\d{2}:?\\d{2}|Z)$', ' ', regex=True)\n",
    "                    .str.replace(r'[\\/\\.]', '-', regex=True)\n",
    "                    .str.strip()\n",
    "                    .str.replace(r'[^\\w\\s:-]', '', regex=True))\n",
    "df['Join_Date'] = pd.to_datetime(df['Join_Date'], errors='coerce', infer_datetime_format=True)\n",
    "df['Join_Date'] = df['Join_Date'].fillna(pd.Timestamp('2024-01-01'))\n",
    "\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7d764346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "\n",
    "#\n",
    "manual_map = {\n",
    "    'pk': 'Pakistan',\n",
    "    'pak': 'Pakistan',\n",
    "    'usa': 'United States',\n",
    "    'u.s.a': 'United States',\n",
    "    'Uas':'United States',\n",
    "    'uas': 'United States',\n",
    "    'america': 'United States',\n",
    "    'uk': 'United Kingdom',\n",
    "    'u.k': 'United Kingdom',\n",
    "    'england': 'United Kingdom',\n",
    "    'uae': 'United Arab Emirates',\n",
    "    'emirates': 'United Arab Emirates',\n",
    "    'russia': 'Russian Federation',\n",
    "    'south korea': 'Korea, Republic of',\n",
    "    'north korea': \"Korea, Democratic People's Republic of\",\n",
    "    'viet nam': 'Vietnam',\n",
    "    'brasil': 'Brazil',\n",
    "    'syria': 'Syrian Arab Republic',\n",
    "    'palestine': 'State of Palestine',\n",
    "    'germny':'Germany',\n",
    "    'inda':'India'\n",
    "\n",
    "}\n",
    "\n",
    "# ðŸ§  Function to clean country names\n",
    "def standardize_country(name):\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "                \n",
    "    name_clean = name.strip().lower()\n",
    "    \n",
    "    # Check manual map first\n",
    "    if name_clean in manual_map:\n",
    "        return manual_map[name_clean]\n",
    "    \n",
    "    # Match using pycountry codes and names\n",
    "    for country in pycountry.countries:\n",
    "        if name_clean in [\n",
    "            country.name.lower(),\n",
    "            country.alpha_2.lower(),\n",
    "            country.alpha_3.lower()\n",
    "        ]:\n",
    "            return country.name\n",
    "    \n",
    "    # Return formatted name if no match found\n",
    "    return name.title()\n",
    "\n",
    "# ðŸ§¹ Apply cleaning to the 'country' column\n",
    "df['Country']=df['Country'].apply(standardize_country)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481fc27",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[402], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(k)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# k=list(k)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m         k\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241;43m4\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m+\u001b[39m(k)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "df.sort_values(by='ID',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "130e711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final=df.to_csv('cleaned_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f903f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
